# -*- coding: utf-8 -*-
"""RT_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OiSb2Re06B8CZdneYNFQPlNn9vn5tUWq

## üî¨ Project Title: Arrhythmia Classification Using Machine Learning

### üéØ Objectives

To develop and evaluate a comprehensive ECG analysis framework that:

- ‚úÖ **Implements and compares** an ensemble of optimized machine learning models (e.g., **XGBoost, Random Forest, SVC**) using **probability density function (PDF)**‚Äëbased methodologies.
- ‚úÖ **Bridges the gap** in existing literature by incorporating and assessing **simpler classification algorithms** (e.g., **K‚ÄëNearest Neighbours, Logistic Regression**) alongside complex ensembles.
- ‚úÖ **Designs and trains a convolutional neural network (CNN)** for **image‚Äëbased ECG pattern recognition**, enabling **automated detection** of arrhythmias from ECG signal plots.

### üë• Group Members

| Name               | Roll No. |
|--------------------|----------|
| Sheiladitya Basu   | A006     |
| Tanvi Chavan       | A007     |
| Vaibhav Chavan     | A008     |
| Ronald Chettiar    | A009     |
| Janisa Dabre       | A010     |

### MIT-BIH Arrhythmia Database Overview

The **MIT-BIH Arrhythmia Database** is a widely used benchmark dataset for the study of cardiac arrhythmias and the evaluation of automated ECG analysis algorithms. The dataset was created by the **Massachusetts Institute of Technology (MIT)** and **Beth Israel Hospital** (now Beth Israel Deaconess Medical Center), and has been publicly available since 1980 through **PhysioNet**.

It serves as a standard testbed for:

- Arrhythmia detection  
- Signal processing  
- ECG classification tasks  

---

#### Dataset Characteristics

The database consists of **48 half-hour excerpts** of two-channel ambulatory ECG recordings collected between **1975 and 1979**. These recordings were obtained from **47 subjects**, with one subject contributing two recordings. The dataset includes a variety of ECG signals representing both normal and abnormal heart rhythms.

Of the 48 recordings:
- **23 recordings** were randomly selected from a set of 4,000 long-term (24-hour) ECGs from inpatients (~60%) and outpatients (~40%) at Beth Israel Hospital.
- **25 recordings** were chosen specifically to include **less common but clinically significant arrhythmias** that wouldn't appear frequently in a random sample.

---

#### Annotation Details

Each heartbeat has been **manually annotated by at least two independent cardiologists**, ensuring high-quality reference labels. Any discrepancies were resolved via review.  

- **Total annotated heartbeats**: ~110,000  
- **Each beat is labeled** with a class indicating the type of beat or abnormality.

---

#### Label Description

- **Number of Samples**: 109,446  
- **Number of Categories**: 5  
- **Sampling Frequency**: 125 Hz  

**Classes**:
- `'N': 0` ‚Üí Normal beat  
- `'S': 1` ‚Üí Supraventricular premature beat  
- `'V': 2` ‚Üí Premature ventricular contraction  
- `'F': 3` ‚Üí Fusion of ventricular and normal beat  
- `'Q': 4` ‚Üí Unclassifiable beat

## üõ†Ô∏è Methodology

### üìä Ensemble and Simple Models

- üîπ **Data Loading**
- üîπ **Data Exploration**
- üîπ **Data Cleaning**
- üîπ **Data Preparation & Splitting**
- üîπ **Feature Engineering (PCA)**
- üîπ **Supervised Model Training**  
  &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Ensemble Models: XGBoost, Random Forest, SVC  
  &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Simple Models: Logistic Regression, K-Nearest Neighbours
- üîπ **Model Evaluation**
- üîπ **Detailed Analysis of Best Models**

---

### üß† CNN Approach

- üîπ **Load Train and Test Datasets**
- üîπ **Split into Features (X) and Labels (y)**
- üîπ **Downsample Each Class**  
  &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ 400 samples per class for training  
  &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ 150 samples per class for testing
- üîπ **Convert 1D Signals to 100√ó100 px PNG Images**
- üîπ **Build DataFrames** of Image Filenames & Labels
- üîπ **Create ImageDataGenerators** for Train/Test Sets
- üîπ **Define & Compile 2D CNN Architecture**
- üîπ **Train Model** with `EarlyStopping` & `ModelCheckpoint`
- üîπ **Plot Training Loss & Accuracy**
- üîπ **Evaluate Model** on Test Set  
  &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Accuracy  
  &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Classification Report  
  &nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Confusion Matrix

## **CODE:**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

train_df = pd.read_csv('/content/drive/MyDrive/RT/mitbih_train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/RT/mitbih_test.csv')

# 1. Data Shape
print("Data Shape:", train_df.shape)

# 2. Summary Statistics
print("\nSummary Statistics:")
display(train_df.describe())

# 3. Missing Values
print("\nMissing Values:")
missing_values = train_df.isnull().sum()
missing_percentage = (missing_values / len(train_df)) * 100
missing_info = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})
display(missing_info)

# 4. Duplicate Rows
duplicate_rows = train_df.duplicated().sum()
print("\nDuplicate Rows:", duplicate_rows)

# 5. Target Variable Distribution
target_variable = train_df.iloc[:, -1]
target_counts = target_variable.value_counts()
print("\nTarget Variable Distribution:")
display(target_counts)

# 6. Class Balance
class_percentages = (target_counts / len(train_df)) * 100
print("\nClass Balance:")
display(class_percentages)

# 7. Feature Distributions
# Due to the large number of features, histograms for each feature will not be generated
# in this code block. It is recommended to analyze the distributions using other tools
# or selectively plot histograms for specific features of interest.

target_variable

# Check for missing values and replace with mean
for df in [train_df, test_df]:
  for column in df.columns:
    if df[column].isnull().any():
      df[column].fillna(df[column].mean(), inplace=True)

# Check for duplicate rows and remove them
train_df.drop_duplicates(inplace=True)
test_df.drop_duplicates(inplace=True)

# Extract features and target for training data
X_train = train_df.iloc[:, :-1]
y_train = train_df.iloc[:, -1]

# Extract features and target for testing data
X_test = test_df.iloc[:, :-1]
y_test = test_df.iloc[:, -1]

from sklearn.model_selection import train_test_split

X_train_new, X_val, y_train_new, y_val = train_test_split(
    X_train, y_train, test_size=0.3, random_state=42
)

from sklearn.decomposition import PCA

# Instantiate PCA with n_components=30
pca = PCA(n_components=30)

# Fit PCA on the training data
pca.fit(X_train_new)

# Transform both training and validation data using the fitted PCA model
df_pca_train = pd.DataFrame(pca.transform(X_train_new))
df_pca_val = pd.DataFrame(pca.transform(X_val))

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC, LinearSVC

# Initialize models with default hyperparameters
xgb_model = XGBClassifier()
lgbm_model = LGBMClassifier()
rf_model = RandomForestClassifier()
svc_model = SVC()
linear_svc_model = LinearSVC()

# Train models using the training data
xgb_model.fit(X_train_new, y_train_new)
lgbm_model.fit(X_train_new, y_train_new)
rf_model.fit(X_train_new, y_train_new)
svc_model.fit(X_train_new, y_train_new)
linear_svc_model.fit(X_train_new, y_train_new)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Evaluate the models on the validation set
models = [xgb_model, lgbm_model, rf_model, svc_model, linear_svc_model]
model_names = ['XGBoost', 'LightGBM', 'Random Forest', 'SVC', 'Linear SVC']
results = {}

for model, name in zip(models, model_names):
    y_pred_val = model.predict(X_val)
    accuracy = accuracy_score(y_val, y_pred_val)
    precision = precision_score(y_val, y_pred_val, average='macro')
    recall = recall_score(y_val, y_pred_val, average='macro')
    f1 = f1_score(y_val, y_pred_val, average='macro')
    conf_matrix = confusion_matrix(y_val, y_pred_val)

    results[name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-score': f1,
        'Confusion Matrix': conf_matrix,
    }

# Print and analyze the results for each model
for name, metrics in results.items():
    print(f"Model: {name}")
    print(f"Accuracy: {metrics['Accuracy']:.4f}")
    print(f"Precision: {metrics['Precision']:.4f}")
    print(f"Recall: {metrics['Recall']:.4f}")
    print(f"F1-score: {metrics['F1-score']:.4f}")
    print("Confusion Matrix:\n", metrics['Confusion Matrix'])
    print("-" * 30)

# Select the best-performing model based on the results
# (Consider both overall performance and performance on minority classes)
# Implement logic to determine the best model based on the evaluation metrics
# You can choose the model with the highest F1-score or accuracy, or consider other factors
# such as the confusion matrix and the performance on minority classes.
# Example:
best_model_name = max(results, key=lambda k: results[k]['F1-score'])
print(f"The best-performing model is: {best_model_name}")

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# XGBoost Confusion Matrix
conf_matrix = np.array([
    [14532, 14, 24, 4, 3],
    [128, 285, 4, 0, 1],
    [69, 0, 1043, 6, 2],
    [35, 0, 13, 104, 0],
    [18, 0, 7, 0, 1219]
])

# Class labels
labels = ['N', 'S', 'V', 'F', 'Q']  # or replace with your actual class names

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - XGBoost')
plt.show()

from sklearn.metrics import classification_report

# Get predictions for XGBoost
xgb_y_pred_val = results['XGBoost']['Confusion Matrix'].argmax(axis=1)  # <-- Optional if you only have CM
xgb_y_pred = xgb_model.predict(X_val)

# Print the classification report
print("Class-wise Evaluation Metrics for XGBoost:\n")
print(classification_report(y_val, xgb_y_pred, digits=4))

from sklearn.metrics import classification_report

# Train performance
y_train_pred = xgb_model.predict(X_train_new)

train_accuracy = accuracy_score(y_train_new, y_train_pred)
train_precision = precision_score(y_train_new, y_train_pred, average='macro')
train_recall = recall_score(y_train_new, y_train_pred, average='macro')
train_f1 = f1_score(y_train_new, y_train_pred, average='macro')

print("XGBoost Performance on Training Set:")
print(f"Accuracy: {train_accuracy:.4f}")
print(f"Precision: {train_precision:.4f}")
print(f"Recall: {train_recall:.4f}")
print(f"F1-score: {train_f1:.4f}")
print("\nClassification Report:\n", classification_report(y_train_new, y_train_pred))

import matplotlib.pyplot as plt

# Calculate accuracy
train_acc = accuracy_score(y_train_new, xgb_model.predict(X_train_new))
val_acc = accuracy_score(y_val, xgb_model.predict(X_val))

# Data for plot
labels = ['Train Accuracy', 'Test Accuracy']
scores = [train_acc, val_acc]

# Plot
plt.figure(figsize=(6, 5))
bars = plt.bar(labels, scores, color=['skyblue', 'lightgreen'])
plt.ylim(0, 1.05)
plt.ylabel('Accuracy')
plt.title('XGBoost: Train vs Test Accuracy')

# Annotate with values
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f"{height:.4f}",
             ha='center', fontsize=12)

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# XGBoost Confusion Matrix
conf_matrix = np.array([[14528  ,  14 ,   23  ,   9  ,   3],
 [  130 ,  282  ,   6 ,    0 ,    0],
 [   73   ,  0  ,1036,     9    , 2],
 [   38   ,  0 ,   16 ,   98  ,   0],
 [   18   ,  0   ,  8   ,  0 , 1218]]
)

# Class labels
labels = ['N', 'S', 'V', 'F', 'Q']  # or replace with your actual class names

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - LightGBM')
plt.show()

from sklearn.metrics import classification_report

# Get predictions for XGBoost
lgbm_y_pred_val = results['LightGBM']['Confusion Matrix'].argmax(axis=1)  # <-- Optional if you only have CM
lgbm_y_pred = lgbm_model.predict(X_val)

# Print the classification report
print("Class-wise Evaluation Metrics for LightGBM:\n")
print(classification_report(y_val, lgbm_y_pred, digits=4))

from sklearn.metrics import classification_report

# Train performance
y_train_pred = lgbm_model.predict(X_train_new)

train_accuracy = accuracy_score(y_train_new, y_train_pred)
train_precision = precision_score(y_train_new, y_train_pred, average='macro')
train_recall = recall_score(y_train_new, y_train_pred, average='macro')
train_f1 = f1_score(y_train_new, y_train_pred, average='macro')

print("LightGBM Performance on Training Set:")
print(f"Accuracy: {train_accuracy:.4f}")
print(f"Precision: {train_precision:.4f}")
print(f"Recall: {train_recall:.4f}")
print(f"F1-score: {train_f1:.4f}")
print("\nClassification Report:\n", classification_report(y_train_new, y_train_pred))

import matplotlib.pyplot as plt

# Calculate accuracy
train_acc = accuracy_score(y_train_new, lgbm_model.predict(X_train_new))
val_acc = accuracy_score(y_val, lgbm_model.predict(X_val))

# Data for plot
labels = ['Train Accuracy', 'Test Accuracy']
scores = [train_acc, val_acc]

# Plot
plt.figure(figsize=(6, 5))
bars = plt.bar(labels, scores, color=['skyblue', 'lightgreen'])
plt.ylim(0, 1.05)
plt.ylabel('Accuracy')
plt.title('LightGBM: Train vs Test Accuracy')

# Annotate with values
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f"{height:.4f}",
             ha='center', fontsize=12)

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## **SIMPLE**"""

import pandas as pd

df_test = pd.read_csv('/content/drive/MyDrive/rt/mitbih_test.csv')
df_train = pd.read_csv('/content/drive/MyDrive/rt/mitbih_train.csv')

# Shape and Data Types
print("df_test shape:", df_test.shape)
print("df_train shape:", df_train.shape)
print("\ndf_test data types:\n", df_test.dtypes)
print("\ndf_train data types:\n", df_train.dtypes)

# Descriptive Statistics
print("\ndf_test descriptive statistics:\n", df_test.describe())
print("\ndf_train descriptive statistics:\n", df_train.describe())

# Target Variable Identification
# Assuming the last column is the target variable
target_column_test = df_test.columns[-1]
target_column_train = df_train.columns[-1]

print("\ndf_test target variable:", target_column_test)
print("df_train target variable:", target_column_train)

print("\ndf_test target variable unique values and distribution:\n", df_test[target_column_test].value_counts())
print("\ndf_train target variable unique values and distribution:\n", df_train[target_column_train].value_counts())

# Check for missing values
print("Missing values in df_test:\n", df_test.isnull().sum())
print("\nMissing values in df_train:\n", df_train.isnull().sum())

# Handle missing values (if any) - For example, replace with mean:
# df_test.fillna(df_test.mean(), inplace=True)
# df_train.fillna(df_train.mean(), inplace=True)

# Check for duplicates
print("\nNumber of duplicate rows in df_test:", df_test.duplicated().sum())
print("Number of duplicate rows in df_train:", df_train.duplicated().sum())

# Remove duplicates (if any)
df_test.drop_duplicates(inplace=True)
df_train.drop_duplicates(inplace=True)

from sklearn.model_selection import train_test_split

X = df_train.iloc[:, :-1]
y = df_train.iloc[:, -1]

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier

# Initialize models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Naive Bayes": GaussianNB(),
    "Decision Tree": DecisionTreeClassifier(),
}

# Train models
for model_name, model in models.items():
    model.fit(X_train, y_train)
    print(f"{model_name} trained successfully.")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

for model_name, model in models.items():
    y_pred = model.predict(X_val)
    accuracy = accuracy_score(y_val, y_pred)
    precision = precision_score(y_val, y_pred, average='weighted')  # Adjust 'average' if needed
    recall = recall_score(y_val, y_pred, average='weighted')  # Adjust 'average' if needed
    f1 = f1_score(y_val, y_pred, average='weighted')  # Adjust 'average' if needed

    print(f"{model_name} Evaluation:")
    print(f"  Accuracy: {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")
    print(f"  F1-Score: {f1:.4f}")
    print("-" * 20)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Step 1: Split your dataset (X = features, y = target)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 2: Train your KNN model
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Step 3: Predict on validation set
y_pred_knn = knn.predict(X_val)

# Step 4: Confusion matrix
conf_matrix_knn = confusion_matrix(y_val, y_pred_knn)

# Step 5: Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_knn, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title("K-Nearest Neighbors - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Step 6: Class-wise evaluation
class_report_knn = classification_report(y_val, y_pred_knn, output_dict=True)
class_report_df_knn = pd.DataFrame(class_report_knn).transpose().round(4)

# Display the report
print("\nKNN Class-wise Evaluation Report:")
print(class_report_df_knn)

knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)

import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

# Predict and calculate accuracy
train_acc_knn = accuracy_score(y_train, knn_model.predict(X_train))
val_acc_knn = accuracy_score(y_val, knn_model.predict(X_val))

# Data for plot
labels = ['Train Accuracy', 'Test Accuracy']
scores = [train_acc_knn, val_acc_knn]

# Plot
plt.figure(figsize=(6, 5))
bars = plt.bar(labels, scores, color=['lightcoral', 'lightskyblue'])
plt.ylim(0, 1.05)
plt.ylabel('Accuracy')
plt.title('K-Nearest Neighbors: Train vs Test Accuracy')

# Annotate with values
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f"{height:.4f}",
             ha='center', fontsize=12)

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier(random_state=42)
dtree.fit(X_train, y_train)

y_pred_dtree = dtree.predict(X_val)

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

conf_matrix_dtree = confusion_matrix(y_val, y_pred_dtree)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_dtree, annot=True, fmt='d', cmap='Greens', cbar=False)
plt.title("Decision Tree - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report
import pandas as pd

class_report_dtree = classification_report(y_val, y_pred_dtree, output_dict=True)
class_report_df_dtree = pd.DataFrame(class_report_dtree).transpose().round(4)

print("\nDecision Tree Class-wise Evaluation Report:")
print(class_report_df_dtree)

import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

train_acc_dtree = accuracy_score(y_train, dtree.predict(X_train))
val_acc_dtree = accuracy_score(y_val, dtree.predict(X_val))

# Accuracy values
train_acc_dtree = 0.9835
val_acc_dtree = 0.9565

# Labels and scores
labels = ['Train Accuracy', 'Test Accuracy']
scores = [train_acc_dtree, val_acc_dtree]

# Plot
plt.figure(figsize=(6, 5))
bars = plt.bar(labels, scores, color=['mediumseagreen', 'lightsteelblue'])
plt.ylim(0, 1.05)
plt.ylabel('Accuracy')
plt.title('Decision Tree: Train vs Test Accuracy')

# Annotate with values
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f"{height:.4f}",
             ha='center', fontsize=12)

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

